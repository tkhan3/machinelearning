{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "similarity.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwAiHeHINXI57gNILOnKRH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkhan3/machinelearning/blob/master/similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzbKGAciSfXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "WORD = re.compile(r\"\\w+\")\n",
        "\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
        "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM4A8szpSpjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d53e84fb-dc2d-4c6b-8207-b02ad79744c8"
      },
      "source": [
        "def text_to_vector(text):\n",
        "    words = WORD.findall(text.lower())\n",
        "    return Counter(words)\n",
        "\n",
        "\n",
        "text1 = \"This sentence is similar to a foo bar sentence .\"\n",
        "text2 = \"This is a Foo bar sentence .\"\n",
        "\n",
        "vector1 = text_to_vector(text1)\n",
        "vector2 = text_to_vector(text2)\n",
        "\n",
        "cosine = get_cosine(vector1, vector2)\n",
        "\n",
        "print(\"Cosine:\", cosine)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine: 0.8616404368553293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsOcse0XYS-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "db1f42fe-9a29-42ad-b49a-69e9de73efe5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nldGomLxYvRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1fb9be82-d1e4-4c22-cb9f-acb17154eab4"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3KYha7qYrVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words_1 = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18WJN1JuXoCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import en_core_web_sm\n",
        "from nltk.tokenize import word_tokenize \n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V6U4qRHVjXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanNumbers(text):\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
        "    text = re.sub(r'[^a-zA-Z ]',' ', text)\n",
        "    text = text.lower()\n",
        "    return(text)  \n",
        "\n",
        "def lemmatisation(text):\n",
        "    text = text.lower()\n",
        "    j=''\n",
        "    doc = nlp(text)\n",
        "    for i in doc:\n",
        "        j=j+\" \"+ i.lemma_    \n",
        "    return j.strip()\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    word_tokens = word_tokenize(text) \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words_1] \n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnODVXkjWrBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text1 = \"This sentence is similar to a 123 foo bar sentence .\"\n",
        "text2 = \"This is a Foo bar sentence .\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlX_nsXJWtEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleanNumberstext1 = cleanNumbers(text1)\n",
        "cleanNumberstext2 = cleanNumbers(text2)\n",
        "\n",
        "lemmaText1 = lemmatisation(cleanNumberstext1)\n",
        "lemmaText2 = lemmatisation(cleanNumberstext2)\n",
        "\n",
        "finalText1 = remove_stopwords(lemmaText1)\n",
        "finalText2 = remove_stopwords(lemmaText2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbmxLlPBZJlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e7d2568f-ed6e-4e00-8f71-a8de9f5eda1b"
      },
      "source": [
        "print (finalText1)\n",
        "print (finalText2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence similar foo bar sentence\n",
            "foo bar sentence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oZa4sfcVm75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def get_cosine_sim(*strs): \n",
        "    vectors = [t for t in get_vectors(*strs)]\n",
        "    print (vectors)\n",
        "    return cosine_similarity(vectors)[0][1]\n",
        "def get_vectors(*strs):\n",
        "    text = [t for t in strs]\n",
        "    print (text)\n",
        "    vectorizer = CountVectorizer(text)\n",
        "    vectorizer.fit(text)\n",
        "    print (vectorizer.get_feature_names())\n",
        "    return vectorizer.transform(text).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB6Gn30uZ1LG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e7de91e1-aba3-4cac-f743-81b00cbcfdf8"
      },
      "source": [
        "get_cosine_sim(finalText2,finalText1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['foo bar sentence', 'sentence similar foo bar sentence']\n",
            "['bar', 'foo', 'sentence', 'similar']\n",
            "[array([1, 1, 1, 0]), array([1, 1, 2, 1])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8728715609439696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}